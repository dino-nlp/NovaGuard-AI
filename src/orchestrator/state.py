# NOVAGUARD-AI/src/orchestrator/state.py

from typing import TypedDict, List, Dict, Any, Optional

# Assuming ChangedFile and SharedReviewContext are in src/core/
# Adjust the import path if your structure is different.
from ..core.shared_context import SharedReviewContext, ChangedFile

# It's good practice to define a common structure for findings,
# though the state uses List[Dict[str, Any]] for flexibility as per original design.
# If you want stricter typing for findings, you could define a Pydantic model:
#
# class FindingOutput(TypedDict, total=False):
#     file_path: str
#     line_start: int
#     line_end: Optional[int]
#     col_start: Optional[int]
#     col_end: Optional[int]
#     message_text: str
#     rule_id: str
#     level: str  # e.g., "error", "warning", "note"
#     tool_name: str
#     code_snippet: Optional[str]
#     suggestion: Optional[str]
#     raw_tool_output: Optional[Any]


class GraphState(TypedDict):
    """
    Represents the shared state of the code review graph.
    This state is passed between nodes, and each node can read from
    and write to it.
    """

    # --- Input and Contextual Data ---
    shared_context: SharedReviewContext
    """
    Contextual information about the PR/commit, repository,
    and GitHub event. Loaded at the beginning.
    """

    files_to_review: List[ChangedFile]
    """
    A list of files (with their content and potentially diff hunks)
    that have been identified for review in the current run.
    Typically populated by the 'prepare_review_files_node'.
    """

    # --- Intermediate Results from Tools and Agents ---
    tier1_tool_results: Dict[str, List[Dict[str, Any]]]
    """
    Results from traditional, non-LLM tools (linters, SAST scanners like Semgrep).
    The main dictionary key is the tool's name (e.g., "pylint", "semgrep").
    The value is a list of finding dictionaries produced by that tool.
    Each finding dictionary should conform to a standardized structure.
    Example: {"pylint": [{"file_path": "...", "line_start": ..., "message_text": ..., ...}]}
    """

    agent_findings: List[Dict[str, Any]]
    """
    A consolidated list of all findings (observations, suggestions, errors)
    generated by the specialized LLM agents (StyleGuardian, BugHunter, etc.).
    Each item in the list is a dictionary representing a single finding.
    This list is typically appended to by each agent node.
    """

    # --- Final Output ---
    final_sarif_report: Optional[Dict[str, Any]]
    """
    The fully formed SARIF report JSON object (as a dictionary).
    This is typically generated by the 'generate_sarif_report_node'
    using both tier1_tool_results and agent_findings.
    """

    # --- Operational Data ---
    error_messages: List[str]
    """
    A list to accumulate any error messages encountered during the
    execution of graph nodes. Helps in debugging and reporting issues.
    """

    # Optional: Could be useful for tracking or conditional logic, initialize to 0.
    # processed_files_count: int

    # Note on state updates in LangGraph:
    # By default, when a node returns a dictionary with keys matching GraphState,
    # the values for those keys in the state are replaced.
    # For fields that need to be accumulated (e.g., `agent_findings`, `error_messages`),
    # this accumulation logic is typically handled either:
    # 1. Within the node itself (node reads current list, appends, returns new list).
    # 2. Using `Annotated` from `typing_extensions` with an operator like `operator.add`
    #    when defining the StateGraph, to specify how updates to a field should be merged.
    #    Example: `agent_findings: Annotated[List[Dict[str, Any]], operator.add]`
    #    This requires `StateGraph(GraphState)` definition and edge configuration.
    #    This file only defines the TypedDict, not the graph execution logic.